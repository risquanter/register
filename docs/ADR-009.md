# ADR-009: Compositional Risk Aggregation via Identity

**Status:** Accepted  
**Date:** 2026-01-17  
**Tags:** architecture, domain-model, zio-prelude, aggregation, monoid

---

## Context

The risk register models a **tree of risks** where:
- **Leaf nodes** (`RiskLeaf`) define distribution parameters (probability, loss bounds)
- **Branch nodes** (`RiskPortfolio`) aggregate children but have no distribution of their own

After Monte Carlo simulation, every node needs a **loss distribution** for LEC visualization—including aggregates. The challenge is: how do mid-level nodes acquire distributions when only leaves have parameters?

---

## Decision

### Uniform Result Type via `RiskResult`

All nodes—leaf and branch—share the same result type:

```scala
case class RiskResult(
  name: String,
  outcomes: Map[TrialId, Loss],  // Sparse: only non-zero trials
  nTrials: Int
) extends LossDistribution with LECCurve
```

| Node Type | How `RiskResult` is produced |
|-----------|------------------------------|
| `RiskLeaf` | Monte Carlo sampling from metalog distribution |
| `RiskPortfolio` | `Identity[RiskResult].combine(child1, child2)` |

### Trial-Wise Aggregation via ZIO Prelude Identity

```scala
// LossDistribution.scala
given identity: Identity[RiskResult] with {
  def identity: RiskResult = RiskResult("", Map.empty, 0)
  
  def combine(a: => RiskResult, b: => RiskResult): RiskResult = {
    require(a.nTrials == b.nTrials, 
      s"Cannot merge results with different trial counts: ${a.nTrials} vs ${b.nTrials}")
    RiskResult(
      name = if (a.name.nonEmpty) a.name else b.name,
      outcomes = LossDistribution.merge(a, b),
      nTrials = a.nTrials
    )
  }
}
```

### Outer Join Merge Semantics

```scala
// LossDistribution.scala
def merge(distributions: LossDistribution*): Map[TrialId, Loss] = {
  val allTrialIds = distributions.foldLeft(Set.empty[TrialId])(_ ++ _.trialIds())
  
  allTrialIds.map { trial =>
    trial -> distributions.foldLeft(0L)((acc, d) => acc + d.outcomeOf(trial))
  }.toMap
}
```

**Example:**
```
Trial 1:  RiskA=1000, RiskB=500  → Aggregate=1500
Trial 2:  RiskA=0,    RiskB=200  → Aggregate=200  (RiskA missing = 0)
Trial 3:  RiskA=300,  RiskB=0    → Aggregate=300  (RiskB missing = 0)
```

### Tree Simulation with Bottom-Up Aggregation

```scala
// Simulator.scala
case portfolio: RiskPortfolio =>
  for {
    childResults <- ZIO.collectAllPar(
      portfolio.children.map(simulateTreeInternal)
    )
    aggregated <- ZIO.attempt {
      val combined = childResults.map(_.result).reduce { (a, b) =>
        Identity[RiskResult].combine(a, b)
      }
      RiskTreeResult.Branch(portfolio.id, combined, childResults.toVector)
    }
  } yield aggregated
```

---

## Data Model Summary

### Input: Risk Tree

```
RiskNode (sealed trait)
├── RiskLeaf: Has distribution parameters
│   - distributionType: "expert" | "lognormal"
│   - probability: Probability
│   - minLoss, maxLoss: Option[Long]
│   - (expert fields: percentiles, quantiles)
│
└── RiskPortfolio: Structural only
    - children: Array[RiskNode]
```

### Output: Result Tree

```
RiskTreeResult (sealed trait)
├── Leaf
│   - id: String
│   - result: RiskResult  ← Sampled from distribution
│
└── Branch
    - id: String
    - result: RiskResult  ← Aggregated via Identity.combine
    - children: Vector[RiskTreeResult]
```

### Serialization: LEC Response

```
LECCurveData
├── id, name: String
├── curve: Vector[LECPoint]      ← Derived from RiskResult
├── quantiles: Map[String, Double]  ← p50, p90, p95, p99
└── children: Option[Vector[LECCurveData]]
```

---

## Why This Works

### 1. Same Type, Same LEC

Since both leaves and aggregates are `RiskResult`:
- Both implement `LECCurve` trait
- Both have `probOfExceedance(threshold: Loss): BigDecimal`
- Both can generate `LECCurveData` via `LECGenerator`

### 2. Algebraic Properties Enable Caching

The `Identity` instance satisfies monoid laws:

| Property | Equation | Benefit |
|----------|----------|---------|
| Associativity | `(a ⊕ b) ⊕ c = a ⊕ (b ⊕ c)` | Order-independent aggregation |
| Left identity | `∅ ⊕ a = a` | Safe empty portfolios |
| Right identity | `a ⊕ ∅ = a` | Safe partial trees |

This enables:
- **Incremental recomputation**: If child C changes, recompute only ancestors
- **Parallel aggregation**: Combine children in any grouping
- **Subtree caching**: Cache `RiskResult` per node (see ADR-005)

### 3. Sparse Storage for Efficiency

```scala
outcomes: Map[TrialId, Loss]  // Only trials with non-zero loss
```

Low-probability risks have few entries (e.g., 2% probability → ~200 entries per 10,000 trials).

---

## Diagram

```
                    Input Tree                         Result Tree
                    
              ┌─────────────────┐              ┌─────────────────────┐
              │  RiskPortfolio  │              │       Branch        │
              │    "ops-risk"   │              │   result: Combined  │
              │ (no parameters) │    ────►     │   A ⊕ B ⊕ C         │
              └────────┬────────┘              └──────────┬──────────┘
                       │                                  │
         ┌─────────────┼─────────────┐      ┌─────────────┼─────────────┐
         │             │             │      │             │             │
    ┌────┴────┐   ┌────┴────┐   ┌────┴────┐ │        │         │
    │ Leaf A  │   │ Leaf B  │   │ Leaf C  │ ▼        ▼         ▼
    │ p=0.25  │   │ p=0.10  │   │ p=0.05  │ Leaf A   Leaf B    Leaf C
    │ lognorm │   │ expert  │   │ lognorm │ result:A result:B  result:C
    └─────────┘   └─────────┘   └─────────┘ (sampled)(sampled) (sampled)
                       
              Monte Carlo Sampling          Trial-wise Summation
              ─────────────────────────────────────────────────────►
```

---

## Code Smells

### ❌ Type Switching on Node Level

```scala
// BAD: Different types for different levels
def getLEC(node: AnyNode): LEC = node match {
  case leaf: LeafResult => leafToLEC(leaf)
  case agg: AggregateResult => aggregateToLEC(agg)  // Different logic!
}

// GOOD: Uniform type, uniform processing
def getLEC(result: RiskResult): LECCurveData =
  LECGenerator.generateLEC(result)  // Same for all levels
```

### ❌ Manual Trial Alignment

```scala
// BAD: Manual trial-by-trial summation
def aggregate(children: List[RiskResult]): Map[TrialId, Loss] = {
  val allTrials = children.flatMap(_.outcomes.keys).distinct
  allTrials.map { t =>
    t -> children.map(_.outcomes.getOrElse(t, 0L)).sum
  }.toMap
}

// GOOD: Use Identity.combine
def aggregate(children: List[RiskResult]): RiskResult =
  children.reduce(Identity[RiskResult].combine)
```

### ❌ Recompute Full Tree on Change

```scala
// BAD: Invalidate everything
def onNodeChanged(nodeId: NodeId): Task[Unit] =
  for
    tree <- getFullTree
    _ <- simulateEntireTree(tree)  // O(n) even for single leaf change
  yield ()

// GOOD: Invalidate path to root, recompute lazily (see ADR-005)
def onNodeChanged(nodeId: NodeId): Task[Unit] =
  cache.invalidateAncestors(nodeId)  // O(depth)
```

---

## Implementation Locations

| Component | Location | Purpose |
|-----------|----------|---------|
| `RiskResult` | `domain/data/LossDistribution.scala` | Leaf result type |
| `RiskResultGroup` | `domain/data/LossDistribution.scala` | Aggregate with children |
| `Identity[RiskResult]` | `domain/data/LossDistribution.scala` | ZIO Prelude instance |
| `LossDistribution.merge` | `domain/data/LossDistribution.scala` | Outer join logic |
| `RiskTreeResult` | `domain/data/TreeResult.scala` | ⚠️ **DEPRECATED** - see note below |
| `Simulator.simulateTree` | `services/helper/Simulator.scala` | Bottom-up aggregation |
| `LECGenerator` | `simulation/LECGenerator.scala` | `RiskResult` → `LECCurveData` |

### ⚠️ RiskTreeResult Deprecation

`RiskTreeResult` is deprecated and will be removed. The new architecture caches `RiskResult` per node in `RiskResultCache`, eliminating the need to carry a separate tree of results.

See **[ADR-015-proposal.md](./ADR-015-proposal.md)** for the replacement pattern:
- **`RiskResultResolver.ensureCached(nodeId)`**: Returns cached or freshly simulated result
- **Cache as source of truth**: No parallel result tree structure needed
- **Tree structure for invalidation only**: `TreeIndex` provides O(depth) ancestor lookup

---

## Property Tests

The `Identity` laws are verified in `IdentityPropertySpec.scala`:

```scala
test("associativity: (a ⊕ b) ⊕ c = a ⊕ (b ⊕ c)") { ... }
test("left identity: ∅ ⊕ a = a") { ... }
test("right identity: a ⊕ ∅ = a") { ... }
```

---

## References

- ADR-005: Cached Subtree Aggregates (uses this pattern for O(depth) recomputation)
- ADR-014: RiskResult Caching Strategy (cache design)
- ADR-015-proposal: Cache Integration - RiskResultResolver pattern (replaces RiskTreeResult)
- ZIO Prelude: https://zio.dev/zio-prelude/
- `IdentityPropertySpec.scala`: Property tests for monoid laws
