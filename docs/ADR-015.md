# ADR-015: RiskResult Cache Integration

**Status:** Accepted  
**Date:** 2026-02-09  
**Supersedes:** Parts of ADR-014 (refines cache wiring details)

---

## Context

`RiskResultCache` (ADR-014) stores per-node simulation outcomes. This ADR defines how the cache integrates with the simulation and query APIs.

### Key Insight

The tree STRUCTURE comes from `RiskNode` (the definition stored in Irmin). The simulation RESULTS are `RiskResult` per node, cached by `NodeId`. The cache is the single source of truth for simulation outputs.

---

## Decision

### Cache-Direct Architecture

```
Simulation → Cache (RiskResult per node) → Query cache directly
```

### Core Abstraction: RiskResultResolver

Separate service that provides the `ensureCached` primitive. Cache remains pure storage.

```scala
trait RiskResultResolver:
  /** Core primitive: ensure result is cached, simulate if needed */
  def ensureCached(nodeId: NodeId): Task[RiskResult]
  
  /** Ensure multiple nodes are cached */
  def ensureCachedAll(nodeIds: Set[NodeId]): Task[Map[NodeId, RiskResult]]
```

All query methods become simple `map` compositions over this primitive.

### Data Flow

```
Irmin (persistent)     ←→     RiskTreeRepository
        ↓
    RiskNode (tree definition)
        ↓
    RiskResultResolver.ensureCached(nodeId)
        ↓
    [cache hit?] → return cached RiskResult
    [cache miss?] → simulate subtree → cache all → return RiskResult
        ↓
    LECGenerator / probOfExceedance (pure transforms)
```

---

## API Design

### RiskResultResolver Service (New)

```scala
trait RiskResultResolver:
  /** Core primitive: ensure result is cached, simulate if needed */
  def ensureCached(tree: RiskTree, nodeId: NodeId, includeProvenance: Boolean = false): Task[RiskResult]
  
  /** Ensure multiple nodes are cached */
  def ensureCachedAll(tree: RiskTree, nodeIds: Set[NodeId], includeProvenance: Boolean = false): Task[Map[NodeId, RiskResult]]

class RiskResultResolverLive(
  cache: TreeCacheManager,
  config: SimulationConfig,
  tracing: Tracing,
  metrics: Metrics
) extends RiskResultResolver:
  
  def ensureCached(nodeId: NodeId): Task[RiskResult] =
    cache.get(nodeId).flatMap {
      case Some(r) => ZIO.succeed(r)
      case None    => simulateSubtree(nodeId)
    }
```

### Query APIs (Compositions over ensureCached)

```scala
// LEC curve for single node
def getLECCurve(nodeId: NodeId): Task[Vector[(Long, Double)]] =
  resolver.ensureCached(nodeId).map(LECGenerator.generateCurvePoints(_))

// Exceedance probability for single node
def probOfExceedance(nodeId: NodeId, threshold: Loss): Task[BigDecimal] =
  resolver.ensureCached(nodeId).map(_.probOfExceedance(threshold))

// LEC curves for multiple nodes (shared tick domain)
def getLECCurvesMulti(nodeIds: Set[NodeId]): Task[Map[NodeId, Vector[(Long, Double)]]] =
  resolver.ensureCachedAll(nodeIds).map(LECGenerator.generateCurvePointsMulti)
```

### RiskResultCache (Pure Storage)

```scala
trait RiskResultCache:
  def get(nodeId: NodeId): UIO[Option[RiskResult]]
  def put(nodeId: NodeId, result: RiskResult): UIO[Unit]
  def invalidate(nodeId: NodeId): UIO[List[NodeId]]  // clears node + ancestors
  def clear: UIO[Unit]
  def size: UIO[Int]
```

Cache knows nothing about simulation. It's pure get/put/invalidate.

---

## Simulation Logic

### simulateSubtree

Cache-aware simulation that traverses only the necessary subtree:

```scala
def simulateSubtree(nodeId: NodeId): Task[RiskResult] =
  for
    node <- lookupNodeDefinition(nodeId)  // from RiskTree/RiskNode structure
    result <- node match
      case leaf: RiskLeaf =>
        // Simulate leaf directly
        simulateLeaf(leaf).tap(r => cache.put(nodeId, r))
        
      case portfolio: RiskPortfolio =>
        // Recurse to children, combine
        for
          childResults <- ZIO.foreach(portfolio.children)(child =>
            cache.get(child.id).flatMap {
              case Some(r) => ZIO.succeed(r)  // reuse cached
              case None    => simulateSubtree(child.id)  // recurse
            }
          )
          combined = childResults.combineAll  // using Identity[RiskResult]
          _ <- cache.put(nodeId, combined)
        yield combined
  yield result
```

### Simulation Direction

The traversal is top-down (from requested node to leaves), but computation is bottom-up (leaves combine into parents):

```
1. Start at requested node           ← top-down TRAVERSAL
2. Recurse to children  
3. Recurse to leaves
4. Simulate leaf → RiskResult → CACHE IT   ← bottom-up COMPUTATION
5. Combine children → parent → CACHE IT
6. Continue up to requested node
7. Return node's RiskResult
```

---

## Cache Invalidation

### RiskResultCache Interface

```scala
trait RiskResultCache:
  def get(nodeId: NodeId): UIO[Option[RiskResult]]
  def put(nodeId: NodeId, result: RiskResult): UIO[Unit]
  def invalidate(nodeId: NodeId): UIO[List[NodeId]]  // clears node + ancestors
  def clear: UIO[Unit]
  def size: UIO[Int]
```

### Invalidation Uses TreeIndex

```scala
def invalidate(nodeId: NodeId): UIO[List[NodeId]] =
  for
    path <- ZIO.succeed(treeIndex.ancestorPath(nodeId))  // [root, ..., parent, nodeId]
    _    <- cacheRef.update(cache => cache -- path)
  yield path
```

---

## Code Smells

### ❌ Cache-Aware Simulation Logic in Service Layer

```scala
// BAD: Service layer manages cache hits/misses inline
def getLEC(nodeId: NodeId) =
  cache.get(nodeId).flatMap {
    case Some(r) => ZIO.succeed(generateCurvePoints(r))
    case None    => simulateSubtree(nodeId).tap(cache.put(nodeId, _)).map(generateCurvePoints)
  }

// GOOD: Delegate to RiskResultResolver, query is a pure transform
def getLEC(nodeId: NodeId) =
  resolver.ensureCached(tree, nodeId).map(generateCurvePoints)
```

### ❌ Separate Cache and Simulation Calls Per Query

```scala
// BAD: Each query independently checks cache then simulates
def probOfExceedance(nodeId: NodeId, t: Loss) =
  cache.get(nodeId).flatMap {
    case Some(r) => ZIO.succeed(r.probOfExceedance(t))
    case None    => simulate(nodeId).tap(cache.put(nodeId, _)).map(_.probOfExceedance(t))
  }

// GOOD: Single ensureCached primitive, all queries compose over it
def probOfExceedance(nodeId: NodeId, t: Loss) =
  resolver.ensureCached(tree, nodeId).map(_.probOfExceedance(t))
```

### ❌ Persisting Simulation Results to Irmin

```scala
// BAD: Store RiskResult in Irmin (large, ephemeral, reproducible)
irminClient.set(s"results/$nodeId", result.toJson)

// GOOD: Cache in-memory only — results are reproducible from tree definition
// Irmin stores RiskNode (definition), cache stores RiskResult (computed)
cache.put(nodeId, result)
```

---

## Invalidation Walkthrough

### Tree Structure

```
        portfolio (root)
           /    \
      ops-risk   market-risk
        /   \
    cyber  hardware
```

### Initial State (all cached)

```
cache["cyber"]       = RiskResult(outcomes=...)
cache["hardware"]    = RiskResult(outcomes=...)
cache["ops-risk"]    = RiskResult(outcomes=...)  // combined cyber+hardware
cache["market-risk"] = RiskResult(outcomes=...)
cache["portfolio"]   = RiskResult(outcomes=...)  // combined all
```

### Scenario: User Modifies "hardware" Probability

**Step 1: Invalidation triggered**

```scala
cache.invalidate(hardwareId)

// TreeIndex.ancestorPath(hardware) returns:
// List(portfolio, ops-risk, hardware)

// Cache entries cleared:
cache.remove(hardware)
cache.remove(ops-risk)
cache.remove(portfolio)
```

**After invalidation:**

```
cache["cyber"]       = RiskResult(...)   ✓ PRESERVED (not ancestor)
cache["hardware"]    = <empty>           ✗ CLEARED
cache["ops-risk"]    = <empty>           ✗ CLEARED (ancestor)
cache["market-risk"] = RiskResult(...)   ✓ PRESERVED (sibling branch)
cache["portfolio"]   = <empty>           ✗ CLEARED (ancestor)
```

---

**Step 2: User requests LEC for "hardware"**

```scala
getLECCurve(hardwareId)

// cache.get(hardwareId) → None (cache miss)
// simulateSubtree(hardwareId) called
```

For hardware (a leaf):
1. Simulate leaf → `RiskResult`
2. `cache.put("hardware", result)`
3. Return result

**After this request:**

```
cache["cyber"]       = RiskResult(...)   unchanged
cache["hardware"]    = RiskResult(...)   ✓ REPOPULATED
cache["ops-risk"]    = <empty>           still empty
cache["market-risk"] = RiskResult(...)   unchanged
cache["portfolio"]   = <empty>           still empty
```

---

**Step 3: User requests LEC for "portfolio"**

```scala
getLECCurve(portfolioId)

// cache.get(portfolioId) → None (miss)
// simulateSubtree(portfolioId) called
```

Traversal:
1. Portfolio has children: `[ops-risk, market-risk]`
2. For `ops-risk`: cache miss → recurse
   - Children: `[cyber, hardware]`
   - `cyber`: cache **HIT** → reuse
   - `hardware`: cache **HIT** → reuse (from step 2)
   - Combine → `cache.put("ops-risk", combined)`
3. For `market-risk`: cache **HIT** → reuse
4. Combine `[ops-risk-result, market-risk-result]`
5. `cache.put("portfolio", combined)`

**What got recomputed:**
- `ops-risk` combination (not simulation, just `combineAll`)
- `portfolio` combination

**What was reused (no simulation):**
- `cyber` (cached)
- `hardware` (cached from step 2)
- `market-risk` (cached)

---

## Direction Summary

| Operation | Direction | Scope |
|-----------|-----------|-------|
| Invalidation | Bottom-up | Node → root (ancestors) |
| Simulation (on miss) | Top-down then bottom-up | Requested node → leaves → back up |
| Combine | Bottom-up | Leaves → requested node |

---

## Irmin Interaction

Irmin stores the **tree definition** (`RiskNode`). It does NOT store simulation results.

```
Irmin (persistent)
    ↓
RiskNode (tree definition)
    ↓
Simulation (in-memory, via RiskResultResolver)
    ↓
RiskResult per node (cached in-memory via TreeCacheManager, NOT in Irmin)
```

Simulation results are not persisted to Irmin — they are computed and cached in-memory only.

---

## Implementation Status

| Phase | Status |
|-------|--------|
| `RiskResultResolver` service | ✅ Implemented |
| Node lookup via `TreeIndex` | ✅ Implemented |
| `RiskTreeServiceLive` uses `resolver.ensureCached` | ✅ Implemented |
| Cache hit/miss behavior tested | ✅ Implemented |
| Cache invalidation via Irmin notifications | Deferred to Irmin integration phase |

---

## Open Questions (Resolved)

1. **Simulation parameters in cache key?**  
   ✅ Resolved: Key is `NodeId` only. Simulation parameters come from `SimulationConfig` (service-wide).  
   Cache is invalidated on tree structure changes, not config changes.

2. **lookupNodeDefinition implementation?**  
   ✅ Resolved: `TreeIndex` built at tree construction time. `RiskTree.index.nodes: Map[NodeId, RiskNode]`  
   provides O(1) lookup. `RiskResultResolver` methods take `RiskTree` parameter.

3. **Provenance on cache hit?**  
   ✅ Resolved: Provenance is embedded in `RiskResult.provenances: List[NodeProvenance]`.  
   On cache hit, the cached provenance is returned. No re-simulation needed.

---

## Consequences

### Positive

- Cleaner separation: definition (RiskNode) vs results (RiskResult)
- Cache becomes single source of truth for simulation outputs
- Fine-grained invalidation and recomputation
- Simpler return types from simulation

### Negative

- Requires refactoring simulation layer
- Need to ensure cache is always populated before query
- `lookupNodeDefinition` requires node index or tree walking

---

## Related

- **ADR-014:** RiskResult Caching Strategy (parent ADR)
- **ADR-014-appendix-b:** Cache Invalidation Flow
